{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import time\n",
    "\n",
    "from Bio import SeqIO\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prokaryote_fasta_fp = '/home/jklynch/host/project/viral-learning/data/500_ArcFake_training_set.fasta'\n",
    "input_phage_fasta_fp = '/home/jklynch/host/project/viral-learning/data/500_ArcPhage_training_set.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_training_h5_fp = '/home/jklynch/host/project/viral-learning/data/500_phage_prok_cnn_training.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_fasta_sequences(fasta_fp):\n",
    "    seq_count = 0\n",
    "    with open(fasta_fp, 'rt') as phage_file:\n",
    "        for line in phage_file:\n",
    "            if line.startswith('>'):\n",
    "                seq_count += 1\n",
    "            else:\n",
    "                pass\n",
    "    return seq_count    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_fasta_sequence_length(fasta_fp):\n",
    "    for record in SeqIO.parse(fasta_fp, \"fasta\"):\n",
    "        return len(record.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(h5_file, dset_name, sample_count, sequence_length, im_height):\n",
    "    return h5_file.create_dataset(\n",
    "        name=dset_name,\n",
    "        shape=(sample_count, im_height, sequence_length - im_height + 1, 4),\n",
    "        maxshape=(None, im_height, sequence_length - im_height + 1, 4),\n",
    "        dtype=np.float64,\n",
    "        chunks=(1, im_height, sequence_length - im_height + 1, 4),\n",
    "        compression='gzip',\n",
    "        compression_opts=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_stop(N, M):\n",
    "    \"\"\"\n",
    "    N is sequence length\n",
    "    M is image height\n",
    "    S is stride\n",
    "    \n",
    "    N=13\n",
    "    M=4\n",
    "    S=1\n",
    "    1 2 3 4 5 6 7 8 9 10 11 12 13\n",
    "    a c g t a c g t a c  g  t  a        start stop\n",
    "                                        i     N-M+i\n",
    "    a1 c2 g3 t4 a5 c6 g7  t8  a9  c10   0     9\n",
    "    c2 g3 t4 a5 c6 g7 t8  a9  c10 g11   1     10\n",
    "    g3 t4 a5 c6 g7 t8 a9  c10 g11 t12   2     11\n",
    "    t4 a5 c6 g7 t8 a9 c10 g11 t12 a13   3     12\n",
    "    \"\"\"\n",
    "    start_stop = np.zeros((M, 2), dtype=np.int32)\n",
    "    start_stop[:, 0] = np.arange(M, dtype=np.int32)\n",
    "    start_stop[:, 1] = (N-M) + np.arange(M, dtype=np.int32)\n",
    "    print(start_stop)\n",
    "    #start_stop = start_stop + np.arange(N-M+1, dtype=np.int32).reshape((N-M+1,1))\n",
    "    return start_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2D_sequence(seq, start_stop_indices):\n",
    "    \"\"\"\n",
    "    seq=acgtacgtacgta\n",
    "    start_stop_indices=((0,9),(1,10),(2,11),(3,12))\n",
    "    \n",
    "    seq_2d=(\n",
    "        (acgtacgtac),\n",
    "        (cgtacgtacg),\n",
    "        (gtacgtacgt),\n",
    "        (tacgtacgta)\n",
    "    )\n",
    "    \"\"\"\n",
    "    seq_2d = []\n",
    "    for start, stop in start_stop_indices:  #get_start_stop(N=len(seq), M=M):\n",
    "        seq_2d.append(tuple(seq[start:stop]))\n",
    "    return tuple(seq_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nucleotide_to_channels = {\n",
    "    'A':[1.0, 0.0, 0.0, 0.0],\n",
    "    'C':[0.0, 1.0, 0.0, 0.0],\n",
    "    'G':[0.0, 0.0, 1.0, 0.0],\n",
    "    'T':[0.0, 0.0, 0.0, 1.0]}\n",
    "    #'U':[0.00, 0.00, 0.00, 0.00, 0.00],\n",
    "    #'N':[0.20, 0.20, 0.20, 0.20, 0.20],\n",
    "    #'R':[0.50, 0.00, 0.50, 0.00, 0.00],\n",
    "    #'M':[0.50, 0.50, 0.00, 0.00, 0.00], # A or C\n",
    "    #'S':[0.00, 0.50, 0.50, 0.00, 0.00], # C or G\n",
    "    #'K':[0.00, 0.00, 0.333, 0.333, 0.333], # G, T, or U\n",
    "    #'W':[0.333, 0.00, 0.00, 0.333, 0.333], # A, T, or U\n",
    "    #'Y':[0.00, 0.333, 0.00, 0.333, 0.333]} # C, T, ur U\n",
    "\n",
    "def translate_seq_to_training_input(seq, M, start_stop_indices, verbose=False):\n",
    "    \"\"\"\n",
    "    M is image height\n",
    "    \n",
    "    \"\"\"\n",
    "    ##S = 1\n",
    "    N = len(seq)\n",
    "    ##M = 100\n",
    "    training_data = np.zeros((M, N-M+1, 4))\n",
    "    for start, partial_seq in enumerate(get_2D_sequence(seq, start_stop_indices=start_stop_indices)):\n",
    "        #print(partial_seq)\n",
    "        for n, nucleotide in enumerate(partial_seq):\n",
    "            training_data[start, n, :] = nucleotide_to_channels[nucleotide]\n",
    "        if verbose:\n",
    "            print(partial_seq)\n",
    "            print(training_data[start, :, :])\n",
    "\n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(fasta_fp, seq_length, im_height, im_limit):\n",
    "\n",
    "    #max_samples, im_height, im_width, n_channels = dset.shape\n",
    "    #seq_length = im_height + im_width - 1\n",
    "    #print('max_samples     : {}'.format(max_samples))\n",
    "    #print('image height    : {}'.format(im_height))\n",
    "    #print('image width     : {}'.format(im_width))\n",
    "    #print('channels        : {}'.format(n_channels))\n",
    "    print('sequence length : {}'.format(seq_length))\n",
    "\n",
    "    start_stop_indices = get_start_stop(seq_length, im_height)\n",
    "\n",
    "    # i is the current output row index\n",
    "    # r is the current input row index\n",
    "    # they may not be equal\n",
    "    i = 0\n",
    "    t0 = time.time()\n",
    "    for r, record in enumerate(itertools.islice(SeqIO.parse(fasta_fp, \"fasta\"), im_limit)):\n",
    "        if len(record.seq) != seq_length:\n",
    "            print('{} record.seq length: {} != {}'.format(r, len(record.seq), seq_length))\n",
    "        else:\n",
    "            # dset[i, :, :, :] = \n",
    "            try:\n",
    "                t = translate_seq_to_training_input(\n",
    "                    seq=str(record.seq),\n",
    "                    start_stop_indices=start_stop_indices,\n",
    "                    M=im_height)\n",
    "                i += 1\n",
    "                yield t\n",
    "            except KeyError:\n",
    "                print('found a sequence with ambigous base'.format())\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('finished 100 records in {:5.2f}s'.format(r, time.time()-t0))\n",
    "            t0 = time.time()\n",
    "\n",
    "    # return the number of images written to dset\n",
    "    ##return i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_phage_prok_cnn_training_file(input_phage_fp, input_prok_fp, output_h5_fp, im_height, im_limit=None):\n",
    "    phage_seq_count = count_fasta_sequences(fasta_fp=input_phage_fp)\n",
    "    print('{} sequences in file \"{}\"'.format(phage_seq_count, input_phage_fp))\n",
    "\n",
    "    prok_seq_count = count_fasta_sequences(fasta_fp=input_prok_fp)\n",
    "    print('{} sequences in file \"{}\"'.format(prok_seq_count, input_prok_fp))\n",
    "\n",
    "    phage_seq_length = first_fasta_sequence_length(fasta_fp=input_phage_fp)\n",
    "    prok_seq_length = first_fasta_sequence_length(fasta_fp=input_prok_fp)    \n",
    "    \n",
    "    if phage_seq_length == prok_seq_length:\n",
    "        seq_length = phage_seq_length\n",
    "        print('phage and prokaryote sequence length is {}'.format(seq_length))\n",
    "        print('image height : {}'.format(im_height))\n",
    "        print('image width  : {}'.format(seq_length - im_height + 1))\n",
    "    else:\n",
    "        raise Exception('phage and prokaryote sequence lengths are different')\n",
    "    \n",
    "    os.remove(output_h5_fp)\n",
    "    with h5py.File(output_h5_fp, 'w') as h5_file:\n",
    "        phage_dset = create_dataset(\n",
    "            h5_file=h5_file,\n",
    "            dset_name=os.path.basename(input_phage_fp),\n",
    "            sample_count=phage_seq_count,\n",
    "            sequence_length=seq_length,\n",
    "            im_height=im_height)\n",
    "        \n",
    "        max_samples, im_height, im_width, n_channels = phage_dset.shape\n",
    "        for i, seq_image in enumerate(get_images(fasta_fp=input_phage_fp, im_height=im_height, seq_length=seq_length, im_limit=im_limit)):\n",
    "            phage_dset[i, :, :, :] = seq_image\n",
    "\n",
    "        # resize the data set\n",
    "        (s, m, n, c) = phage_dset.shape\n",
    "        phage_dset.resize((i, m, n, c))\n",
    "        \n",
    "        prok_dset = create_dataset(\n",
    "            h5_file=h5_file,\n",
    "            dset_name=os.path.basename(input_prok_fp),\n",
    "            sample_count=prok_seq_count,\n",
    "            sequence_length=seq_length,\n",
    "            im_height=im_height)\n",
    "        \n",
    "        max_samples, im_height, im_width, n_channels = prok_dset.shape\n",
    "        for i, seq_image in enumerate(get_images(fasta_fp=input_prok_fp, im_height=im_height, seq_length=seq_length, im_limit=im_limit)):\n",
    "            prok_dset[i, :, :, :] = seq_image\n",
    "        \n",
    "        # resize the data set\n",
    "        (s, m, n, c) = prok_dset.shape\n",
    "        prok_dset.resize((i, m, n, c))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_phage_prok_cnn_training_file(\n",
    "    input_phage_fp=input_phage_fasta_fp,\n",
    "    input_prok_fp=input_prokaryote_fasta_fp,\n",
    "    output_h5_fp=output_training_h5_fp,\n",
    "    im_height=100,\n",
    "    im_limit=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
