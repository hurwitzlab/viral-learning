{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare training on samples in the order they occur in the file to training on samples out-of-order (permuted).\n",
    "Try to compare speed of loading data using read_direct to just slicing H5 datatsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Lambda\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.utils\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from vl.data import load_kmer_range_batches_h5, load_kmer_random_batches_h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore', UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_dim):\n",
    "    \"\"\"\n",
    "    Return a 2-layer network.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "# train on shuffled samples\n",
    "train_test_fp = '../data/training_testing.h5'\n",
    "\n",
    "# 25 samples from the bacteria dataset\n",
    "# 25 samples from the virus dataset\n",
    "batch_size = 50\n",
    "\n",
    "with h5py.File(train_test_fp, 'r') as train_test_file:\n",
    "    bacteria_dset = train_test_file['/clean-bact/training1/extract/kmers/kmer_file1']\n",
    "    virus_dset = train_test_file['/clean-vir/training1/extract/kmers/kmer_file1']\n",
    "\n",
    "    model = build_model(input_dim=bacteria_dset.shape[1])\n",
    "    \n",
    "    # use mini-batch training\n",
    "    # record loss and accuracy after each 'generation' (for lack of a better term)\n",
    "    generations = 2*20\n",
    "    batches_per_generation = 100\n",
    "    print('{} training generations = {} training samples'.format(\n",
    "        generations, generations * batches_per_generation * batch_size))\n",
    "    \n",
    "    # divide the data into shuffled training and validation sets\n",
    "    bacteria_index = np.random.permutation(bacteria_dset.shape[0])\n",
    "    training_fraction = 7 * bacteria_dset.shape[0] // 8\n",
    "    print('bacteria training_fraction: {}'.format(training_fraction))\n",
    "    bacteria_training_index = bacteria_index[:training_fraction]\n",
    "    bacteria_validation_index = bacteria_index[training_fraction:]\n",
    "\n",
    "    virus_index = np.random.permutation(virus_dset.shape[0])\n",
    "    training_fraction = 7 * virus_dset.shape[0] // 8\n",
    "    print('virus training fraction: {}'.format(training_fraction))\n",
    "    virus_training_index = virus_index[:training_fraction]\n",
    "    virus_validation_index = virus_index[training_fraction:]\n",
    "\n",
    "    validation_batches = min(len(bacteria_validation_index), len(virus_validation_index)) // (batch_size // 2)\n",
    "    print('{} validation batches = {} validation samples'.format(\n",
    "        validation_batches, validation_batches * batch_size))\n",
    "    \n",
    "    shuffled_history = model.fit_generator(\n",
    "        generator=load_kmer_random_batches_h5(\n",
    "            'random training',\n",
    "            bacteria_dset=bacteria_dset,\n",
    "            bacteria_subsample=bacteria_training_index,\n",
    "            virus_dset=virus_dset,\n",
    "            virus_subsample=virus_training_index,\n",
    "            half_batch_size=batch_size // 2\n",
    "        ),\n",
    "        # there is no advantage to permuting the validation samples\n",
    "        # and there may be a speed advantage to reading them in order\n",
    "        validation_data=load_kmer_random_batches_h5(\n",
    "            'random validation',\n",
    "            bacteria_dset=bacteria_dset,\n",
    "            bacteria_subsample=bacteria_validation_index,\n",
    "            virus_dset=virus_dset,\n",
    "            virus_subsample=virus_validation_index,\n",
    "            half_batch_size=batch_size // 2\n",
    "        ),\n",
    "        epochs=generations,\n",
    "        steps_per_epoch=batches_per_generation,\n",
    "        validation_steps=validation_batches,\n",
    "        workers=2\n",
    "    )\n",
    "print('finished in {:5.2f}s'.format(time.time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history, title):\n",
    "    training_performance_df = pd.DataFrame(data=history.history, index=range(1, generations + 1))\n",
    "    training_performance_df.index.name = 'generation'\n",
    "    training_performance_df.head()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(training_performance_df.index, training_performance_df.loss, training_performance_df.val_loss)\n",
    "    plt.title('{}\\nTraining and Validation Loss'.format(title))\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['training', 'validation'])\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(training_performance_df.index, training_performance_df.acc, training_performance_df.val_acc)\n",
    "    plt.title('{}\\nTraining and Validation Accuracy'.format(title))\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(['training', 'validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(shuffled_history, 'Shuffled Training Samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "# train on unshuffled samples\n",
    "train_test_fp = '../data/training_testing.h5'\n",
    "\n",
    "# 25 samples from the bacteria dataset\n",
    "# 25 samples from the virus dataset\n",
    "batch_size = 50\n",
    "\n",
    "with h5py.File(train_test_fp, 'r') as train_test_file:\n",
    "    bacteria_dset = train_test_file['/clean-bact/training1/extract/kmers/kmer_file1']\n",
    "    virus_dset = train_test_file['/clean-vir/training1/extract/kmers/kmer_file1']\n",
    "\n",
    "    model = build_model(input_dim=bacteria_dset.shape[1])\n",
    "    \n",
    "    # use mini-batch training\n",
    "    # record loss and accuracy after each 'generation' (for lack of a better term)\n",
    "    generations = 2*20\n",
    "    batches_per_generation = 100\n",
    "    print('{} training generations = {} training samples'.format(\n",
    "        generations, generations * batches_per_generation * batch_size))\n",
    "    \n",
    "    # divide the data into un-shuffled training and validation sets\n",
    "    bacteria_training_sample_count = 7 * bacteria_dset.shape[0] // 8\n",
    "    virus_training_sample_count = 7 * virus_dset.shape[0] // 8\n",
    "\n",
    "    validation_batches = (bacteria_dset.shape[0] - bacteria_training_sample_count) // (batch_size // 2)\n",
    "    print('{} validation batches = {} validation samples'.format(\n",
    "        validation_batches, validation_batches * batch_size))\n",
    "    \n",
    "    unshuffled_history = model.fit_generator(\n",
    "        generator=load_kmer_range_batches_h5(\n",
    "            name='range training',\n",
    "            bacteria_dset=bacteria_dset,\n",
    "            bacteria_range=(0, bacteria_training_sample_count),\n",
    "            virus_dset=virus_dset,\n",
    "            virus_range=(0, virus_training_sample_count),\n",
    "            half_batch_size=batch_size // 2,\n",
    "            shuffle_batch=False\n",
    "        ),\n",
    "        # there is no advantage to permuting the validation samples\n",
    "        # and there may be a speed advantage to reading them in order\n",
    "        validation_data=load_kmer_range_batches_h5(\n",
    "            name='range validation',\n",
    "            bacteria_dset=bacteria_dset,\n",
    "            bacteria_range=(bacteria_training_sample_count, bacteria_dset.shape[0]),\n",
    "            virus_dset=virus_dset,\n",
    "            virus_range=(virus_training_sample_count, virus_dset.shape[0]),\n",
    "            half_batch_size=batch_size // 2,\n",
    "            shuffle_batch=False\n",
    "        ),\n",
    "        epochs=generations,\n",
    "        steps_per_epoch=batches_per_generation,\n",
    "        validation_steps=validation_batches\n",
    "    )\n",
    "print('finished in {:5.2f}s'.format(time.time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(unshuffled_history, 'UnShuffled Training Samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
